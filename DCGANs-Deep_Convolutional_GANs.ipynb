{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNWxO0Y/AiTrAZHozynSMCZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4hLsoL9qV1Xj"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter"]},{"cell_type":"markdown","source":["### Discriminator Architecture:\n","###### (3, 64, 64) --> (64, 32, 32)\n","###### (64, 32, 32) --> (128, 16, 16)\n","###### (128, 16, 16) --> (256, 8, 8)\n","###### (256, 8, 8) --> (512, 4, 4)\n","###### (512, 4, 4) --> (1, 1, 1)"],"metadata":{"id":"PReDruqlrMR2"}},{"cell_type":"code","source":["class Discriminator(nn.Module):\n","  def __init__(self, img_channels):\n","    super(Discriminator, self).__init__()\n","    self.discriminator = nn.Sequential(\n","        # Layer 1 - (Input: (batch_size, 3, 64, 64)) --> (Output: (batch_size, 64, 32, 32))\n","        # Paper described - no batch norm in 1st layer\n","        nn.Conv2d(img_channels, 64, kernel_size=4, stride=2, padding=1),\n","        nn.LeakyReLU(0.2),\n","\n","        # Layer 2 - (Input: (batch_size, 64, 32, 32)) --> (Output: (batch_size, 128, 16, 16))\n","        nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        # Layer 3 - (Input: (batch_size, 128, 16, 16)) --> (Output: (batch_size, 256, 8, 8))\n","        nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        # Layer 4 - (Input: (batch_size, 256, 8, 8)) --> (Output: (batch_size, 512, 4, 4))\n","        nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        # Layer 5 - (Input: (batch_size, 512, 4, 4)) --> (Output: (batch_size, 1, 1, 1))\n","        # Using Sigmoid so that output is between 0(fake) and 1(real)\n","        nn.Conv2d(512, 1, kernel_size=4, stride=2, padding=0),\n","        nn.Sigmoid(),\n","    )\n","\n","  def forward(self, x):\n","    return self.discriminator(x)"],"metadata":{"id":"txSNeTazXi0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Generator Architecture\n","###### (100, 1, 1) --> (1024, 4, 4)\n","###### (1024, 4, 4) --> (512, 8, 8)\n","###### (512, 8, 8) --> (256, 16, 16)\n","###### (256, 16, 16) --> (128, 32, 32)\n","###### (128, 32, 32) --> (3, 64, 64)"],"metadata":{"id":"iNy_W8H4q4M0"}},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self, img_channels, latent_dim):\n","    super(Generator, self).__init__()\n","    self.generator = nn.Sequential(\n","        # Layer 1: (Input: (batch_size, latent_dim=100, 1, 1)) --> (Output: (batch_size, 1024, 4, 4))\n","        nn.ConvTranspose2d(latent_dim, 1024, kernel_size = 4, stride = 1, padding = 0),\n","        nn.BatchNorm2d(1024),\n","        nn.ReLU(),\n","\n","        # Layer 2: (Input: (batch_size, 1024, 4, 4)) --> (Output: (batch_size, 512, 8, 8))\n","        nn.ConvTranspose2d(1024, 512, kernel_size = 4, stride = 2, padding = 1),\n","        nn.BatchNorm2d(512),\n","        nn.ReLU(),\n","\n","        # Layer 3: (Input: (batch_size, 512, 8, 8)) --> (Output: (batch_size, 256, 16, 16))\n","        nn.ConvTranspose2d(512, 256, kernel_size = 4, stride = 2, padding = 1),\n","        nn.BatchNorm2d(256),\n","        nn.ReLU(),\n","\n","        # Layer 4: (Input: (batch_size, 256, 16, 16)) --> (Output: (batch_size, 128, 32, 32))\n","        nn.ConvTranspose2d(256, 128, kernel_size = 4, stride = 2, padding = 1),\n","        nn.BatchNorm2d(128),\n","        nn.ReLU(),\n","\n","        # Layer 5: (Input: (batch_size, 128, 32, 32)) --> (Output: (batch_size, img_channels=3, 64, 64))\n","        # Using Tanh so that output is betwwen -1 and 1, since we will be normalizing our images\n","        nn.ConvTranspose2d(128, img_channels, kernel_size = 4, stride = 2, padding = 1),\n","        nn.Tanh(),\n","    )\n","\n","  def forward(self, x):\n","    return self.generator(x)"],"metadata":{"id":"FBtIstxQptMV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_weights(model):\n","  for m in model.modules():\n","    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n","      nn.init.normal_(m.weight.data, 0, 0.02)"],"metadata":{"id":"WzgOiL9SyhyZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def test():\n","  batch_size, img_channels, H, W = 32, 1, 64, 64\n","  x = torch.randn((batch_size, img_channels, H, W))\n","  discriminator = Discriminator(img_channels)\n","  init_weights(discriminator)\n","  assert discriminator(x).shape == (batch_size, 1, 1, 1)\n","  generator = Generator(latent_dim = 100, img_channels=img_channels)\n","  init_weights(generator)\n","  y = torch.randn((batch_size, 100, 1, 1))\n","  assert generator(y).shape == (batch_size, img_channels, 64, 64)\n","\n","test()"],"metadata":{"id":"7GiUKfq6wwVl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img_channels, latent_dim = 1, 100\n","lr = 3e-4\n","batch_size = 128\n","img_size = 64\n","num_epochs = 3"],"metadata":{"id":"1dSQrGogzkTe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initializing discriminator and its optimizer\n","discriminator = Discriminator(img_channels)\n","init_weights(discriminator)\n","opt_disc = optim.Adam(discriminator.parameters(), lr = lr, betas = (0.5, 0.999))\n","\n","# Initializing generator and its optimizer\n","generator = Generator(img_channels=img_channels, latent_dim=latent_dim)\n","init_weights(generator)\n","opt_gen = optim.Adam(generator.parameters(), lr = lr, betas = (0.5, 0.999))\n","\n","criterion = nn.BCELoss()"],"metadata":{"id":"4l1_MCIjSLQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Loading and Transforming data\n","transforms = transforms.Compose(\n","    [\n","        transforms.Resize(img_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, ), (0.5, )),\n","    ]\n",")\n","\n","dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms,\n","                       download=True)\n","loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","fixed_noise = torch.randn(32, latent_dim, 1, 1)\n","writer_real = SummaryWriter(f\"logs/real\")\n","writer_fake = SummaryWriter(f\"logs/fake\")\n","step = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIL9lPitTcRs","executionInfo":{"status":"ok","timestamp":1718544456876,"user_tz":-330,"elapsed":20731,"user":{"displayName":"Aansh Samyani","userId":"02529855507825789970"}},"outputId":"735b50a5-0571-4c40-cb5d-68a742416ba0","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:09<00:00, 1094507.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 134326.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:01<00:00, 845333.91it/s] \n"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 10595399.76it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","for epoch in range(num_epochs):\n","  for batch_index, (real_img, real_label) in tqdm(enumerate(loader), total=len(loader)):\n","    ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n","    ### BCE Loss = −wn​[yn​⋅logxn​+(1−yn​)⋅log(1−xn​)], so either maximis the above expression or minimize negative of that\n","    ### First Term: log(D(x))\n","    D_x = discriminator(real_img).view(-1)\n","    loss_d_real = criterion(D_x, torch.ones_like(D_x))\n","\n","    ### Second Term: log(1-D(G(z)))\n","    random_noise_z = torch.randn((batch_size, latent_dim, 1, 1))\n","    G_z = generator(random_noise_z)\n","    D_G_z = discriminator(G_z).view(-1)\n","    loss_d_fake = criterion(D_G_z, torch.zeros_like(D_G_z))\n","\n","    ### Total Loss == Average\n","    loss_d = (loss_d_real + loss_d_fake)/2\n","    discriminator.zero_grad()\n","    loss_d.backward(retain_graph = True)\n","    opt_disc.step()\n","\n","    ### Train Generator: min log(1 - D(G(z))) which is same as max log(D(G(z)) which is same as min -log(D(G(z))) (1st term of BCE)\n","    gen_D_G_z = discriminator(G_z).view(-1)\n","    loss_g = criterion(gen_D_G_z, torch.ones_like(gen_D_G_z))\n","    generator.zero_grad()\n","    loss_g.backward()\n","    opt_gen.step()\n","\n","    ls_gen_loss = []\n","    ls_disc_loss = []\n","    if batch_index % 100 == 0:\n","      print(f\"Gen Loss: {loss_g}\")\n","      print(f\"Disc Loss: {loss_d}\")\n","      ls_gen_loss.append(loss_g)\n","      ls_disc_loss.append(loss_d)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXP1aKDPUjXv","outputId":"048789a7-7d73-4d25-f3fd-494734393cc1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 1/469 [00:11<1:32:26, 11.85s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 2.2882027626037598\n","Disc Loss: 0.10390563309192657\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 101/469 [18:39<1:10:59, 11.57s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 4.632757663726807\n","Disc Loss: 0.00883081927895546\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 201/469 [37:09<49:31, 11.09s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 1.0620778799057007\n","Disc Loss: 0.5736242532730103\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 301/469 [55:20<30:15, 10.81s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 1.8106060028076172\n","Disc Loss: 0.6237796545028687\n"]},{"output_type":"stream","name":"stderr","text":[" 86%|████████▌ | 401/469 [1:12:58<11:46, 10.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 1.072310209274292\n","Disc Loss: 0.6497573852539062\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 469/469 [1:24:50<00:00, 10.85s/it]\n","  0%|          | 1/469 [00:11<1:28:16, 11.32s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 1.1321178674697876\n","Disc Loss: 0.6212272644042969\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 101/469 [19:02<1:12:02, 11.75s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 0.9239950776100159\n","Disc Loss: 0.6096317172050476\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 201/469 [38:20<50:10, 11.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 0.763047456741333\n","Disc Loss: 0.687522292137146\n"]},{"output_type":"stream","name":"stderr","text":[" 64%|██████▍   | 301/469 [56:50<31:55, 11.40s/it]"]},{"output_type":"stream","name":"stdout","text":["Gen Loss: 0.6072092652320862\n","Disc Loss: 0.6305333375930786\n"]},{"output_type":"stream","name":"stderr","text":[" 71%|███████   | 334/469 [1:03:12<25:39, 11.40s/it]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"fGMLxtqFgwC7"},"execution_count":null,"outputs":[]}]}